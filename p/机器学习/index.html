<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="Â≠òÊîæÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜËÆ∫„ÄÅÁÆóÊ≥ïÂíåÂÆûÁé∞Ôºå‰ª•Âèä‰∏Ä‰∫õÂÖ∑‰Ωì‰æãÂ≠êÁöÑÂ∞ÅË£Ö">
<title>Êú∫Âô®Â≠¶‰π†</title>

<link rel='canonical' href='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/'>

<link rel="stylesheet" href="/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css"><meta property='og:title' content="Êú∫Âô®Â≠¶‰π†">
<meta property='og:description' content="Â≠òÊîæÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜËÆ∫„ÄÅÁÆóÊ≥ïÂíåÂÆûÁé∞Ôºå‰ª•Âèä‰∏Ä‰∫õÂÖ∑‰Ωì‰æãÂ≠êÁöÑÂ∞ÅË£Ö">
<meta property='og:url' content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/'>
<meta property='og:site_name' content='CA77'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-09-30T20:11:51&#43;08:00'/><meta property='article:modified_time' content='2024-09-30T20:11:51&#43;08:00'/>
<meta name="twitter:title" content="Êú∫Âô®Â≠¶‰π†">
<meta name="twitter:description" content="Â≠òÊîæÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜËÆ∫„ÄÅÁÆóÊ≥ïÂíåÂÆûÁé∞Ôºå‰ª•Âèä‰∏Ä‰∫õÂÖ∑‰Ωì‰æãÂ≠êÁöÑÂ∞ÅË£Ö">
    <link rel="shortcut icon" href="/favicon.png" />
<style>
    :root {
        --sys-font-family: "Noto Sans SC";
        --zh-font-family: "Noto Serif SC";
        --base-font-family: "Fredoka";
        --code-font-family: "Inconsolata";
        --article-font-family: "Bitter", "Noto Serif SC";
    }
</style>

<script>
    (function () {
        const customFont = document.createElement("link");
        customFont.href = "https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,100..900;1,100..900&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    })();

    (function () {
        const customFont = document.createElement("link");
        customFont.href = "https://fonts.googleapis.com/css2?family=Fredoka:wght@300..700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    })();

    (function () {
        const customFont = document.createElement("link");
        customFont.href = "https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@200..900&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    })();

    (function () {
        const customFont = document.createElement("link");
        customFont.href = "https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    })();

    (function () {
        const customFont = document.createElement("link");
        customFont.href = "https://fonts.googleapis.com/css2?family=Inconsolata:wght@200..900&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    })();
</script>

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="ÂàáÊç¢ËèúÂçï">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu17806192823286815243.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">üç•</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">CA77</a></h1>
            <h2 class="site-description">Huazhong University of Science and Technology, Wuhan, China</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://space.bilibili.com/438302027'
                        target="_blank"
                        title="Bilibili"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-bilibili"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 10a4 4 0 0 1 4 -4h10a4 4 0 0 1 4 4v6a4 4 0 0 1 -4 4h-10a4 4 0 0 1 -4 -4v-6z" /><path d="M8 3l2 3" /><path d="M16 3l-2 3" /><path d="M9 13v-2" /><path d="M15 11v2" /></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://github.com/FlowerCA77'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-github"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" /></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='/p/%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86/'
                        
                        title="Profile"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-user-heart"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 7a4 4 0 1 0 8 0a4 4 0 0 0 -8 0" /><path d="M6 21v-2a4 4 0 0 1 4 -4h.5" /><path d="M18 22l3.35 -3.284a2.143 2.143 0 0 0 .005 -3.071a2.242 2.242 0 0 0 -3.129 -.006l-.224 .22l-.223 -.22a2.242 2.242 0 0 0 -3.128 -.006a2.143 2.143 0 0 0 -.006 3.071l3.355 3.296z" /></svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/p/%E9%AB%98%E7%AD%89%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6/' >
                
                
                
                    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-atom"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12v.01" /><path d="M19.071 4.929c-1.562 -1.562 -6 .337 -9.9 4.243c-3.905 3.905 -5.804 8.337 -4.242 9.9c1.562 1.561 6 -.338 9.9 -4.244c3.905 -3.905 5.804 -8.337 4.242 -9.9" /><path d="M4.929 4.929c-1.562 1.562 .337 6 4.243 9.9c3.905 3.905 8.337 5.804 9.9 4.242c1.561 -1.562 -.338 -6 -4.244 -9.9c-3.905 -3.905 -8.337 -5.804 -9.9 -4.242" /></svg>
                
                <span>Adv. Quantum Mechanics</span>
            </a>
        </li>
        
        
        <li >
            <a href='/p/%E9%AB%98%E7%AD%89%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86/' >
                
                
                
                    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-test-pipe"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M20 8.04l-12.122 12.124a2.857 2.857 0 1 1 -4.041 -4.04l12.122 -12.124" /><path d="M7 13h8" /><path d="M19 15l1.5 1.6a2 2 0 1 1 -3 0l1.5 -1.6z" /><path d="M15 3l6 6" /></svg>
                
                <span>Adv. Statistical Physics</span>
            </a>
        </li>
        
        
        <li >
            <a href='/categories/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                
                <span>Categories</span>
            </a>
        </li>
        
        
        <li >
            <a href='/p/%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86/' >
                
                
                
                    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-user-heart"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 7a4 4 0 1 0 8 0a4 4 0 0 0 -8 0" /><path d="M6 21v-2a4 4 0 0 1 4 -4h.5" /><path d="M18 22l3.35 -3.284a2.143 2.143 0 0 0 .005 -3.071a2.242 2.242 0 0 0 -3.129 -.006l-.224 .22l-.223 -.22a2.242 2.242 0 0 0 -3.128 -.006a2.143 2.143 0 0 0 -.006 3.071l3.355 3.296z" /></svg>
                
                <span>Profile</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>ÊöóËâ≤Ê®°Âºè</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">ÁõÆÂΩï</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#ÁÆÄ‰ªã">ÁÆÄ‰ªã</a></li>
    <li><a href="#ÁêÜËÆ∫">ÁêÜËÆ∫</a></li>
    <li><a href="#ÊñπÊ≥ï">ÊñπÊ≥ï</a>
      <ol>
        <li><a href="#ÁõëÁù£Â≠¶‰π†--supervised-learning">ÁõëÁù£Â≠¶‰π† ‚Äî Supervised Learning</a></li>
        <li><a href="#Êó†ÁõëÁù£Â≠¶‰π†--unsupervised-learning">Êó†ÁõëÁù£Â≠¶‰π† ‚Äî Unsupervised Learning</a></li>
        <li><a href="#ÂçäÁõëÁù£Â≠¶‰π†--semi-supervised-learning">ÂçäÁõëÁù£Â≠¶‰π† ‚Äî Semi-Supervised Learning</a></li>
        <li><a href="#Âº∫ÂåñÂ≠¶‰π†--reinforcement-learning">Âº∫ÂåñÂ≠¶‰π† ‚Äî Reinforcement Learning</a></li>
        <li><a href="#ÈôçÁª¥--dimensionality-reduction">ÈôçÁª¥ ‚Äî Dimensionality Reduction</a></li>
        <li><a href="#Ëá™Â≠¶‰π†--self-learning">Ëá™Â≠¶‰π† ‚Äî Self-Learning</a></li>
      </ol>
    </li>
    <li><a href="#Ê®°Âûã">Ê®°Âûã</a>
      <ol>
        <li><a href="#‰∫∫Â∑•Á•ûÁªèÁΩëÁªú--artificial-neural-network-ann">‰∫∫Â∑•Á•ûÁªèÁΩëÁªú ‚Äî Artificial Neural Network (ANN)</a></li>
        <li><a href="#ÂÜ≥Á≠ñÊ†ë--decision-tree">ÂÜ≥Á≠ñÊ†ë ‚Äî Decision Tree</a></li>
        <li><a href="#ÊîØÊåÅÂêëÈáèÊú∫--support-vector-machine-svm">ÊîØÊåÅÂêëÈáèÊú∫ ‚Äî Support-Vector Machine (SVM)</a></li>
        <li><a href="#ÂõûÂΩíÂàÜÊûê--regression-analysis">ÂõûÂΩíÂàÜÊûê ‚Äî Regression Analysis</a></li>
        <li><a href="#bayes-ÁΩëÁªú--bayesian-network">Bayes ÁΩëÁªú ‚Äî Bayesian Network</a></li>
        <li><a href="#gauss-ËøáÁ®ã--gaussian-process">Gauss ËøáÁ®ã ‚Äî Gaussian Process</a></li>
        <li><a href="#ÈÅó‰º†ÁÆóÊ≥ï--genetic-algorithm">ÈÅó‰º†ÁÆóÊ≥ï ‚Äî Genetic Algorithm</a></li>
        <li><a href="#‰ø°ÂøµÂáΩÊï∞--belief-function">‰ø°ÂøµÂáΩÊï∞ ‚Äî Belief Function</a></li>
        <li><a href="#ËÆ≠ÁªÉÊ®°Âûã">ËÆ≠ÁªÉÊ®°Âûã</a></li>
        <li><a href="#ËÅîÈÇ¶Â≠¶‰π†">ËÅîÈÇ¶Â≠¶‰π†</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">Êú∫Âô®Â≠¶‰π†</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Â≠òÊîæÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜËÆ∫„ÄÅÁÆóÊ≥ïÂíåÂÆûÁé∞Ôºå‰ª•Âèä‰∏Ä‰∫õÂÖ∑‰Ωì‰æãÂ≠êÁöÑÂ∞ÅË£Ö
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Sep 30, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    ÈòÖËØªÊó∂Èïø: 18 ÂàÜÈíü
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="ÊïôÊùê">ÊïôÊùê
</h1><p>Stuart Russell, Peter Novrig. <em>Artificial Intelligence: A Modern Approach</em>, Fourth Edition. ‰∏≠ËØëÊú¨: ‰∫∫Â∑•Êô∫ËÉΩ: Áé∞‰ª£ÊñπÊ≥ï, Âº†ÂçöÈõÖÁ≠âËØë. Âåó‰∫¨: ‰∫∫Ê∞ëÈÇÆÁîµÂá∫ÁâàÁ§æ, 2023.1.</p>
<h1 id="ÊäïÁ®øÁõÆÂΩï">ÊäïÁ®øÁõÆÂΩï
</h1><p><a class="link" href="/p/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%8e%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0%e9%80%9a%e8%ae%ba" >Êú∫Âô®Â≠¶‰π†‰∏éÁõëÁù£Â≠¶‰π†ÈÄöËÆ∫</a></p>
<p><a class="link" href="/p/knn-%e7%ae%97%e6%b3%95/" >\( k \)-ÈÇªËøëÁÆóÊ≥ï ‰∏é \( k\bm d \) Ê†ë ÂèäÂÖ∂Â∫îÁî®</a></p>
<h1 id="Áª™ËÆ∫--introduce">Áª™ËÆ∫ ‚Äî Introduce
</h1><p><em>ÂÜÖÂÆπÊù•Ëá™ : wikipedia</em></p>
<h2 id="ÁÆÄ‰ªã">ÁÆÄ‰ªã
</h2><blockquote>
<p><strong>Machine learning (ML)</strong> is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Quick progress in the field of deep learning, beginning in 2010s, allowed neural networks to surpass many previous approaches in performance.</p>
<p><em>Êú∫Âô®Â≠¶‰π† (ML) ÊòØ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑ‰∏ÄÈó®Â≠¶ÁßëÔºå‰∏ìÊ≥®‰∫éÁ†îÁ©∂‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âπ∂ÂØπÊú™ËßÅËøáÁöÑÊï∞ÊçÆËøõË°åÊ≥õÂåñÔºå‰ªéËÄåËÉΩÂ§üÊâßË°åÊó†ÈúÄÊòéÁ°ÆÊåá‰ª§ÁöÑ‰ªªÂä°ÁöÑÁªüËÆ°ÁÆóÊ≥ïÁöÑÂèëÂ±ïÂíåÁ†îÁ©∂„ÄÇÊ∑±Â∫¶Â≠¶‰π†È¢ÜÂüüÁöÑÂø´ÈÄüËøõÊ≠•Âßã‰∫é 2010 Âπ¥‰ª£Ôºå‰ΩøÂæóÁ•ûÁªèÁΩëÁªúÂú®ÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫Ü‰πãÂâçÁöÑËÆ∏Â§öÊñπÊ≥ï„ÄÇ</em></p>
<p>ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.</p>
<p><em>ML Âú®ËÆ∏Â§öÈ¢ÜÂüüÈÉΩÊúâÂ∫îÁî®ÔºåÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅËØ≠Èü≥ËØÜÂà´„ÄÅÁîµÂ≠êÈÇÆ‰ª∂ËøáÊª§„ÄÅÂÜú‰∏öÂíåÂåªÂ≠¶Á≠â„ÄÇMLÂú®ÂïÜ‰∏öÈóÆÈ¢ò‰∏≠ÁöÑÂ∫îÁî®Ë¢´Áß∞‰∏∫È¢ÑÊµãÂàÜÊûê„ÄÇ</em></p>
<p>Statistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.</p>
<p><em>ÁªüËÆ°Â≠¶ÂíåÊï∞Â≠¶‰ºòÂåñÔºàÊï∞Â≠¶ËßÑÂàíÔºâÊñπÊ≥ïÊûÑÊàê‰∫ÜÊú∫Âô®Â≠¶‰π†ÁöÑÂü∫Á°Ä„ÄÇÊï∞ÊçÆÊåñÊéòÊòØ‰∏é‰πãÁõ∏ÂÖ≥ÁöÑÁ†îÁ©∂È¢ÜÂüüÔºå‰∏ìÊ≥®‰∫éÈÄöËøáÊó†ÁõëÁù£Â≠¶‰π†ËøõË°åÊé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûê (EDA) „ÄÇ</em></p>
<p>From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.</p>
<p><em>‰ªéÁêÜËÆ∫ËßíÂ∫¶Êù•ÁúãÔºå‚ÄúÂèØËÉΩËøë‰ººÊ≠£Á°Æ‚Äù (PAC) Â≠¶‰π†‰∏∫Êú∫Âô®Â≠¶‰π†Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÊèèËø∞Ê°ÜÊû∂„ÄÇ</em></p>
</blockquote>
<h2 id="ÁêÜËÆ∫">ÁêÜËÆ∫
</h2><blockquote>
<p>A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.</p>
<p><em>Â≠¶‰π†ËÄÖÁöÑÊ†∏ÂøÉÁõÆÊ†áÊòØ‰ªéÂÖ∂ÁªèÈ™å‰∏≠ËøõË°åÂΩíÁ∫≥„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊ≥õÂåñÊåáÁöÑÊòØÂ≠¶‰π†Êú∫Âô®Âú®ÁªèÂéÜ‰∫ÜÂ≠¶‰π†Êï∞ÊçÆÈõÜ‰πãÂêéÔºåËÉΩÂ§üÂú®Êú™ËßÅËøáÁöÑÊñ∞ÁöÑÁ§∫‰æã/‰ªªÂä°‰∏äÂáÜÁ°ÆÊâßË°åÁöÑËÉΩÂäõ„ÄÇËÆ≠ÁªÉÁ§∫‰æãÊù•Ëá™‰∏Ä‰∫õÈÄöÂ∏∏Êú™Áü•ÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºàË¢´ËÆ§‰∏∫ÊòØÂèëÁîüÁ©∫Èó¥ÁöÑ‰ª£Ë°®ÊÄßÂàÜÂ∏ÉÔºâÔºåÂ≠¶‰π†ËÄÖÂøÖÈ°ªÊûÑÂª∫‰∏Ä‰∏™ÂÖ≥‰∫éËøô‰∏™Á©∫Èó¥ÁöÑÈÄöÁî®Ê®°ÂûãÔºå‰ª•‰æøÂú®Êñ∞ÊÉÖÂÜµ‰∏ã‰∫ßÁîüË∂≥Â§üÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ</em></p>
<p>The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias‚Äìvariance decomposition is one way to quantify generalization error.</p>
<p><em>Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑËÆ°ÁÆóÂàÜÊûêÂèäÂÖ∂ÊÄßËÉΩÊòØÁêÜËÆ∫ËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÈÄöËøá‚ÄúÂèØËÉΩËøë‰ººÊ≠£Á°ÆÂ≠¶‰π†‚Äù (PAC) Ê®°ÂûãË¢´Áß∞‰∏∫ËÆ°ÁÆóÂ≠¶‰π†ÁêÜËÆ∫„ÄÇÁî±‰∫éËÆ≠ÁªÉÈõÜÊòØÊúâÈôêÁöÑÔºåÊú™Êù•ÊòØ‰∏çÁ°ÆÂÆöÁöÑÔºåÂ≠¶‰π†ÁêÜËÆ∫ÈÄöÂ∏∏‰∏çËÉΩ‰øùËØÅÁÆóÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÁõ∏ÂèçÔºåÊÄßËÉΩÁöÑÊ¶ÇÁéáÊÄßÁïåÈÄöÂ∏∏ÂæàÂ∏∏ËßÅ„ÄÇÂÅèÂ∑Æ-ÊñπÂ∑ÆÂàÜËß£ÊòØÈáèÂåñÊ≥õÂåñËØØÂ∑ÆÁöÑ‰∏ÄÁßçÊñπÊ≥ï„ÄÇ</em></p>
<p>For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.
<em>Âú®Ê≥õÂåñÊÄßËÉΩÊñπÈù¢Ë¶ÅËææÂà∞ÊúÄ‰Ω≥Ë°®Áé∞ÔºåÂÅáËÆæÁöÑÂ§çÊùÇÂ∫¶Â∫îËØ•‰∏éÊï∞ÊçÆËÉåÂêéÁöÑÂáΩÊï∞Â§çÊùÇÂ∫¶Áõ∏ÂåπÈÖç„ÄÇÂ¶ÇÊûúÂÅáËÆæÁöÑÂ§çÊùÇÂ∫¶‰Ωé‰∫éÂáΩÊï∞ÔºåÈÇ£‰πàÊ®°ÂûãÂ∞±‰ºöÂØπÊï∞ÊçÆËøõË°åÊ¨†ÊãüÂêà„ÄÇÂ¶ÇÊûúÁõ∏Â∫îÂú∞Â¢ûÂä†Ê®°ÂûãÁöÑÂ§çÊùÇÂ∫¶ÔºåÈÇ£‰πàËÆ≠ÁªÉËØØÂ∑ÆÂ∞±‰ºöÈôç‰Ωé„ÄÇ‰ΩÜÂ¶ÇÊûúÂÅáËÆæËøá‰∫éÂ§çÊùÇÔºåÈÇ£‰πàÊ®°ÂûãÂ∞±‰ºöÂá∫Áé∞ËøáÊãüÂêàÈóÆÈ¢òÔºåÊ≥õÂåñÊÄßËÉΩÂ∞±‰ºöÂèòÂ∑Æ„ÄÇ</em></p>
<p>In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.</p>
<p><em>Èô§‰∫ÜÊÄßËÉΩËæπÁïåÂ§ñÔºåÂ≠¶‰π†ÁêÜËÆ∫ÂÆ∂ËøòÁ†îÁ©∂Â≠¶‰π†ÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶ÂíåÂèØË°åÊÄß„ÄÇÂú®ËÆ°ÁÆóÂ≠¶‰π†ÁêÜËÆ∫‰∏≠ÔºåÂ¶ÇÊûú‰∏Ä‰∏™ËÆ°ÁÆóÂèØ‰ª•Âú®Â§öÈ°πÂºèÊó∂Èó¥ÂÜÖÂÆåÊàêÔºåÂàôËÆ§‰∏∫ÂÆÉÊòØÂèØË°åÁöÑ„ÄÇÊúâ‰∏§ÁßçÊó∂Èó¥Â§çÊùÇÂ∫¶ÁªìÊûúÔºöÊ≠£Èù¢ÁªìÊûúË°®ÊòéÔºåÊüê‰∫õÁ±ªÂûãÁöÑÂáΩÊï∞ÂèØ‰ª•Âú®Â§öÈ°πÂºèÊó∂Èó¥ÂÜÖÂ≠¶‰π†„ÄÇË¥üÈù¢ÁªìÊûúË°®ÊòéÔºåÊüê‰∫õÁ±ªÂáΩÊï∞Êó†Ê≥ïÂú®Â§öÈ°πÂºèÊó∂Èó¥ÂÜÖÂ≠¶‰π†„ÄÇ</em></p>
</blockquote>
<h2 id="ÊñπÊ≥ï">ÊñπÊ≥ï
</h2><blockquote>
<p>Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the &ldquo;signal&rdquo; or &ldquo;feedback&rdquo; available to the learning system:</p>
<p><em>Êú∫Âô®Â≠¶‰π†ÁöÑÊñπÊ≥ïÈÄöÂ∏∏Ë¢´ÂàÜ‰∏∫‰∏âÂ§ßÁ±ªÔºåËøô‰∏éÂ≠¶‰π†Á≥ªÁªüÁöÑ ‚Äú‰ø°Âè∑‚Äù Êàñ ‚ÄúÂèçÈ¶à‚Äù ÁöÑÊÄßË¥®ÊúâÂÖ≥ÔºåÂØπÂ∫î‰∫é‰∏çÂêåÁöÑÂ≠¶‰π†ËåÉÂºèÔºö</em></p>
<ul>
<li>
<p><strong>Supervised learning</strong>: The computer is presented with example inputs and their desired outputs, given by a &ldquo;teacher&rdquo;, and the goal is to learn a general rule that maps inputs to outputs.</p>
<ul>
<li><em>ÁõëÁù£Â≠¶‰π†ÔºöËÆ°ÁÆóÊú∫Ë¢´Â±ïÁ§∫‰∏Ä‰∫õÁ§∫‰æãËæìÂÖ•ÂíåÂÆÉ‰ª¨ÁöÑÊúüÊúõËæìÂá∫ÔºàÁî±‚ÄúËÄÅÂ∏à‚ÄùÁªôÂá∫ÔºâÔºåÁõÆÁöÑÊòØÂ≠¶‰π†‰∏Ä‰∏™Â∞ÜËæìÂÖ•Êò†Â∞ÑÂà∞ËæìÂá∫ÁöÑÈÄöÁî®ËßÑÂàô„ÄÇ</em></li>
</ul>
</li>
<li>
<p><strong>Unsupervised learning</strong>: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).</p>
<ul>
<li><em>Êó†ÁõëÁù£Â≠¶‰π†ÔºöÂ≠¶‰π†ÁÆóÊ≥ï‰∏çË¢´Áªô‰∫à‰ªª‰ΩïÊ†áÁ≠æÔºåÂÆåÂÖ®Èù†Ëá™Â∑±‰ªéËæìÂÖ•Êï∞ÊçÆ‰∏≠ÂØªÊâæÁªìÊûÑ„ÄÇÊó†ÁõëÁù£Â≠¶‰π†Êó¢ÂèØ‰ª•‰Ωú‰∏∫‰∏ÄÁßçÁõÆÊ†áÔºàÂú®Êï∞ÊçÆ‰∏≠ÂèëÁé∞ÈöêËóèÁöÑÊ®°ÂºèÔºâÔºå‰πüÂèØ‰ª•‰Ωú‰∏∫ÂÆûÁé∞ÂÖ∂‰ªñÁõÆÊ†áÁöÑ‰∏ÄÁßçÊâãÊÆµÔºàÁâπÂæÅÂ≠¶‰π†Ôºâ„ÄÇ</em></li>
</ul>
</li>
<li>
<p><strong>Reinforcement learning</strong>: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that&rsquo;s analogous to rewards, which it tries to maximize.</p>
<ul>
<li><em>Âº∫ÂåñÂ≠¶‰π†ÔºöËÆ°ÁÆóÊú∫Á®ãÂ∫è‰∏éÂä®ÊÄÅÁéØÂ¢É‰∫§‰∫íÔºåÂøÖÈ°ªÂÆåÊàêÊüê‰∏™ÁõÆÊ†áÔºà‰æãÂ¶ÇÈ©æÈ©∂ËΩ¶ËæÜÊàñ‰∏éÂØπÊâãËøõË°åÊ∏∏ÊàèÔºâ„ÄÇÂú®Êé¢Á¥¢ÈóÆÈ¢òÁ©∫Èó¥ÁöÑËøáÁ®ã‰∏≠ÔºåÁ®ãÂ∫è‰ºöÊî∂Âà∞Á±ª‰ºº‰∫éÂ•ñÂä±ÁöÑÂèçÈ¶àÔºåÂπ∂ËØïÂõæÊúÄÂ§ßÂåñËøô‰∫õÂ•ñÂä±„ÄÇ</em></li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="ÁõëÁù£Â≠¶‰π†--supervised-learning">ÁõëÁù£Â≠¶‰π† ‚Äî Supervised Learning
</h3><blockquote>
<p>Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs. The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs. An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.</p>
<p><em>ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï‰ºöÂª∫Á´ã‰∏Ä‰∏™ÂåÖÂê´ËæìÂÖ•ÂíåÊúüÊúõËæìÂá∫ÁöÑÊï∞ÊçÆÈõÜÁöÑÊï∞Â≠¶Ê®°Âûã„ÄÇËØ•Êï∞ÊçÆË¢´Áß∞‰∏∫ËÆ≠ÁªÉÊï∞ÊçÆÔºåÁî±‰∏ÄÁªÑËÆ≠ÁªÉÁ§∫‰æãÁªÑÊàê„ÄÇÊØè‰∏™ËÆ≠ÁªÉÁ§∫‰æãÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ËæìÂÖ•ÂíåÊúüÊúõËæìÂá∫Ôºà‰πüÁß∞‰∏∫ÁõëÁù£‰ø°Âè∑Ôºâ„ÄÇÂú®Êï∞Â≠¶Ê®°Âûã‰∏≠ÔºåÊØè‰∏™ËÆ≠ÁªÉÁ§∫‰æãÁî±‰∏Ä‰∏™Êï∞ÁªÑÊàñÂêëÈáèË°®Á§∫ÔºåÊúâÊó∂Áß∞‰∏∫ÁâπÂæÅÂêëÈáèÔºåËÄåËÆ≠ÁªÉÊï∞ÊçÆÂàôÁî±‰∏Ä‰∏™Áü©ÈòµË°®Á§∫„ÄÇÈÄöËøáÂØπÁõÆÊ†áÂáΩÊï∞ÁöÑËø≠‰ª£‰ºòÂåñÔºåÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÂèØ‰ª•Â≠¶‰π†‰∏Ä‰∏™ÂáΩÊï∞ÔºåÁî®‰∫éÈ¢ÑÊµã‰∏éÊñ∞ËæìÂÖ•Áõ∏ÂÖ≥ÁöÑËæìÂá∫„ÄÇ‰∏Ä‰∏™ÊúÄ‰ºòÂáΩÊï∞‰ΩøÁÆóÊ≥ïËÉΩÂ§üÊ≠£Á°ÆÁ°ÆÂÆöÊú™Âú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Âá∫Áé∞ÁöÑËæìÂÖ•ÁöÑËæìÂá∫„ÄÇÂ¶ÇÊûú‰∏Ä‰∏™ÁÆóÊ≥ïËÉΩÂ§üÂú®‰∏çÊñ≠Â≠¶‰π†ÁöÑËøáÁ®ã‰∏≠ÊèêÈ´òÂÖ∂ËæìÂá∫ÊàñÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÂàôÂèØ‰ª•ËØ¥ËØ•ÁÆóÊ≥ïÂ≠¶‰ºö‰∫ÜÊâßË°åËØ•‰ªªÂä°„ÄÇ</em></p>
<p>Types of supervised-learning algorithms include active learning, classification and regression. Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email. Examples of regression would be predicting the height of a person, or the future temperature.</p>
<p><em>ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÁöÑÁ±ªÂûãÂåÖÊã¨‰∏ªÂä®Â≠¶‰π†„ÄÅÂàÜÁ±ªÂíåÂõûÂΩí„ÄÇÂΩìËæìÂá∫Ë¢´ÈôêÂà∂‰∏∫ÊúâÈôêÁöÑ‰∏ÄÁªÑÂÄºÊó∂Ôºå‰ΩøÁî®ÂàÜÁ±ªÁÆóÊ≥ï„ÄÇÂΩìËæìÂá∫ÂèØËÉΩÂú®‰∏ÄÂÆöËåÉÂõ¥ÂÜÖÂÖ∑Êúâ‰ªª‰ΩïÊï∞ÂÄºÊó∂Ôºå‰ΩøÁî®ÂõûÂΩíÁÆóÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫éÁî®‰∫éËøáÊª§ÁîµÂ≠êÈÇÆ‰ª∂ÁöÑÂàÜÁ±ªÁÆóÊ≥ïÔºåËæìÂÖ•Â∞ÜÊòØ‰∏ÄÂ∞ÅÊñ∞Âà∞ËææÁöÑÁîµÂ≠êÈÇÆ‰ª∂ÔºåËæìÂá∫Â∞ÜÊòØËØ•ÁîµÂ≠êÈÇÆ‰ª∂Â∫îË¢´ÂΩíÊ°£Âà∞Âì™‰∏™Êñá‰ª∂Â§πÁöÑÂêçÁß∞„ÄÇÈ¢ÑÊµãË∫´È´òÊàñÈ¢ÑÊµãÊú™Êù•Ê∏©Â∫¶ÊòØÂõûÂΩíÁÆóÊ≥ïÁöÑ‰∏Ä‰∫õÁ§∫‰æã„ÄÇ</em></p>
<p>Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.</p>
<p><em>Áõ∏‰ººÊÄßÂ≠¶‰π†ÊòØÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™È¢ÜÂüüÔºå‰∏éÂõûÂΩíÂíåÂàÜÁ±ªÂØÜÂàáÁõ∏ÂÖ≥Ôºå‰ΩÜÂÖ∂ÁõÆÊ†áÊòØ‰ΩøÁî®‰∏Ä‰∏™Ë°°Èáè‰∏§‰∏™ÂØπË±°‰πãÈó¥Áõ∏‰ººÂ∫¶ÊàñÁõ∏ÂÖ≥ÊÄßÁöÑÁõ∏‰ººÊÄßÂáΩÊï∞Êù•‰ªéÁ§∫‰æã‰∏≠Â≠¶‰π†„ÄÇÂÆÉÂú®ÊéíÂêç„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅËßÜËßâË∫´‰ªΩË∑üË∏™„ÄÅ‰∫∫ËÑ∏È™åËØÅÂíåËØ¥ËØù‰∫∫È™åËØÅÁ≠âÈ¢ÜÂüüÈÉΩÊúâÂ∫îÁî®„ÄÇ</em></p>
</blockquote>
<h3 id="Êó†ÁõëÁù£Â≠¶‰π†--unsupervised-learning">Êó†ÁõëÁù£Â≠¶‰π† ‚Äî Unsupervised Learning
</h3><blockquote>
<p>Unsupervised learning algorithms find structures in data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction, and density estimation. Unsupervised learning algorithms also streamlined the process of identifying large indel based haplotypes of a gene of interest from pan-genome.</p>
<p><em>Êó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÂèØ‰ª•Âú®Êú™Ê†áËÆ∞„ÄÅÂàÜÁ±ªÊàñÂΩíÁ±ªÁöÑÊï∞ÊçÆ‰∏≠ÂèëÁé∞ÁªìÊûÑ„ÄÇ‰∏éÂìçÂ∫îÂèçÈ¶à‰∏çÂêåÔºåÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï‰ºöËØÜÂà´Êï∞ÊçÆ‰∏≠ÁöÑÂÖ±ÂêåÁÇπÔºåÂπ∂Ê†πÊçÆÊØèÂùóÊñ∞Êï∞ÊçÆ‰∏≠ÊòØÂê¶Â≠òÂú®Ëøô‰∫õÂÖ±ÂêåÁÇπÊù•ÂÅöÂá∫ÂèçÂ∫î„ÄÇÊó†ÁõëÁù£Êú∫Âô®Â≠¶‰π†ÁöÑ‰∏ªË¶ÅÂ∫îÁî®ÂåÖÊã¨ËÅöÁ±ª„ÄÅÈôçÁª¥ÂíåÂØÜÂ∫¶‰º∞ËÆ°„ÄÇÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïËøòÁÆÄÂåñ‰∫Ü‰ªéÊ≥õÂü∫Âõ†ÁªÑ‰∏≠ËØÜÂà´Âü∫Âõ†ÊÑüÂÖ¥Ë∂£Âå∫ÂüüÁöÑÂ§ßÂûãÊèíÂÖ•/Áº∫Â§±Á≠â‰ΩçÂü∫Âõ†Âûã (haplotype) ÁöÑËøáÁ®ã„ÄÇ</em></p>
<p>Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.</p>
<p><em>ËÅöÁ±ªÂàÜÊûêÊòØÂ∞Ü‰∏ÄÁªÑËßÇÊµãÊï∞ÊçÆÂàíÂàÜ‰∏∫Ëã•Âπ≤Â≠êÈõÜÔºàÁß∞‰∏∫Á∞áÔºâÁöÑËøáÁ®ãÔºå‰ΩøÂæóÂêå‰∏ÄÁ∞á‰∏≠ÁöÑËßÇÊµãÊï∞ÊçÆÂú®Ê†πÊçÆÈ¢ÑÂÖàÊåáÂÆöÁöÑ‰∏ÄÊàñÂ§ö‰∏™Ê†áÂáÜÔºàÂ¶ÇÁõ∏‰ººÊÄßÔºâÁöÑÁõ∏‰ººÊÄßÊñπÈù¢Áõ∏‰ººÔºåËÄåÊù•Ëá™‰∏çÂêåÁ∞áÁöÑËßÇÊµãÊï∞ÊçÆÂàô‰∏çÁõ∏‰ºº„ÄÇ‰∏çÂêåÁöÑËÅöÁ±ªÊäÄÊúØÂØπÊï∞ÊçÆÁªìÊûÑÊúâ‰∏çÂêåÁöÑÂÅáËÆæÔºåÈÄöÂ∏∏Áî±‰∏Ä‰∫õÂèÇÊï∞ÔºàÂ¶ÇË∑ùÁ¶ªÊàñÁõ∏‰ººÂ∫¶ÔºâÂÆö‰πâÔºåÂπ∂ÈÄöËøá‰æãÂ¶ÇË∑ùÁ¶ªÊàñÂêå‰∏ÄÁ∞áÊàêÂëò‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÅ‰∏çÂêåÁ∞á‰πãÈó¥ÁöÑÂ∑ÆÂºÇÁ≠âËøõË°åËØÑ‰º∞„ÄÇÂÖ∂‰ªñÊñπÊ≥ïÂàôÂü∫‰∫éÂØÜÂ∫¶ÂíåËΩÆÂªì„ÄÇ</em></p>
<p>A special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.</p>
<p><em>‰∏ÄÁßçÁâπÊÆäÁöÑÊó†ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÁß∞‰∏∫‚ÄúËá™ÁõëÁù£Â≠¶‰π†‚ÄùÔºåÂÆÉÈÄöËøá‰ªéÊï∞ÊçÆÊú¨Ë∫´ÁîüÊàêÁõëÁù£‰ø°Âè∑Êù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇ</em></p>
</blockquote>
<h3 id="ÂçäÁõëÁù£Â≠¶‰π†--semi-supervised-learning">ÂçäÁõëÁù£Â≠¶‰π† ‚Äî Semi-Supervised Learning
</h3><blockquote>
<p>Semi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.</p>
<p><em>ÂçäÁõëÁù£Â≠¶‰π†‰ªã‰∫éÊó†ÁõëÁù£Â≠¶‰π†ÔºàÊ≤°Êúâ‰ªª‰ΩïÊ†áÊ≥®ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºâÂíåÊúâÁõëÁù£Â≠¶‰π†ÔºàÊúâÂÆåÂÖ®Ê†áÊ≥®ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºâ‰πãÈó¥„ÄÇ‰∏Ä‰∫õËÆ≠ÁªÉÁ§∫‰æãÁº∫Â∞ëËÆ≠ÁªÉÊ†áÁ≠æÔºå‰ΩÜËÆ∏Â§öÊú∫Âô®Â≠¶‰π†Á†îÁ©∂‰∫∫ÂëòÂèëÁé∞ÔºåÂú®Â∞ëÈáèÊ†áÊ≥®Êï∞ÊçÆÁöÑËæÖÂä©‰∏ãÔºåÊú™Ê†áÊ≥®Êï∞ÊçÆÂèØ‰ª•ÊòæËëóÊèêÈ´òÂ≠¶‰π†ÂáÜÁ°ÆÊÄß„ÄÇ</em></p>
<p>In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.</p>
<p><em>Âú®Âº±ÁõëÁù£Â≠¶‰π†‰∏≠ÔºåËÆ≠ÁªÉÊ†áÁ≠æÊòØÂô™Â£∞ÁöÑ„ÄÅÊúâÈôêÁöÑÊàñ‰∏çÂáÜÁ°ÆÁöÑÔºõÁÑ∂ËÄåÔºåËøô‰∫õÊ†áÁ≠æÈÄöÂ∏∏Êõ¥ÂÆπÊòìËé∑ÂèñÔºåÂõ†Ê≠§ÂèØ‰ª•ÁîüÊàêÊõ¥Â§ßÁöÑÊúâÊïàËÆ≠ÁªÉÈõÜ„ÄÇ</em></p>
</blockquote>
<h3 id="Âº∫ÂåñÂ≠¶‰π†--reinforcement-learning">Âº∫ÂåñÂ≠¶‰π† ‚Äî Reinforcement Learning
</h3><blockquote>
<p>Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques. Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.</p>
<p><em>Âº∫ÂåñÂ≠¶‰π†ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™È¢ÜÂüüÔºåÂÖ≥Ê≥®ËΩØ‰ª∂‰ª£ÁêÜÂú®ÁéØÂ¢É‰∏≠Â∫îËØ•Â¶Ç‰ΩïÈááÂèñË°åÂä®Ôºå‰ª•ÊúÄÂ§ßÂåñÊüêÁßçÁ¥ØÁßØÂ•ñÂä±ÁöÑÊ¶ÇÂøµ„ÄÇÁî±‰∫éÂÖ∂ÈÄöÁî®ÊÄßÔºåËØ•È¢ÜÂüüÂú®ËÆ∏Â§öÂÖ∂‰ªñÂ≠¶Áßë‰∏≠‰πüÂèóÂà∞Á†îÁ©∂Ôºå‰æãÂ¶ÇÂçöÂºàËÆ∫„ÄÅÊéßÂà∂ÁêÜËÆ∫„ÄÅËøêÁ≠πÂ≠¶„ÄÅ‰ø°ÊÅØËÆ∫„ÄÅÂü∫‰∫éÊ®°ÊãüÁöÑ‰ºòÂåñ„ÄÅÂ§ö‰ª£ÁêÜÁ≥ªÁªü„ÄÅÁæ§‰ΩìÊô∫ËÉΩ„ÄÅÁªüËÆ°Â≠¶ÂíåÈÅó‰º†ÁÆóÊ≥ï„ÄÇÂú®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÁéØÂ¢ÉÈÄöÂ∏∏Ë¢´Ë°®Á§∫‰∏∫È©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ã (MDP) „ÄÇËÆ∏Â§öÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ï‰ΩøÁî®Âä®ÊÄÅËßÑÂàíÊäÄÊúØ„ÄÇÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ï‰∏çÂÅáÂÆöÂØπ MDP ÊúâÁ≤æÁ°ÆÁöÑÊï∞Â≠¶Ê®°ÂûãÁöÑ‰∫ÜËß£ÔºåÂπ∂‰∏îÂú®Á≤æÁ°ÆÊ®°Âûã‰∏çÂèØË°åÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®„ÄÇÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÁî®‰∫éËá™‰∏ªËΩ¶ËæÜÊàñÂ≠¶‰π†‰∏é‰∫∫Á±ªÂØπÊâãÁé©Ê∏∏Êàè„ÄÇ</em></p>
</blockquote>
<h3 id="ÈôçÁª¥--dimensionality-reduction">ÈôçÁª¥ ‚Äî Dimensionality Reduction
</h3><blockquote>
<p>Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables. In other words, it is a process of reducing the dimension of the feature set, also called the &ldquo;number of features&rdquo;. Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). The manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.</p>
<p><em>ÈôçÁª¥ÊòØ‰∏ÄÁßçÈÄöËøáËé∑Âèñ‰∏ªÂèòÈáèÈõÜÊù•ÂáèÂ∞ëËÄÉËôëÁöÑÈöèÊú∫ÂèòÈáèÊï∞ÈáèÁöÑËøáÁ®ã„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂÆÉÊòØ‰∏ÄÁßçÂáèÂ∞ëÁâπÂæÅÈõÜÁª¥Â∫¶Ôºà‰πüÁß∞‰∏∫‚ÄúÁâπÂæÅÊï∞Èáè‚ÄùÔºâÁöÑËøáÁ®ã„ÄÇÂ§ßÂ§öÊï∞ÈôçÁª¥ÊäÄÊúØÂèØ‰ª•Ë¢´ËÆ§‰∏∫ÊòØÁâπÂæÅÊ∂àÈô§ÊàñÊèêÂèñ„ÄÇÈôçÁª¥ÁöÑ‰∏ÄÁßçÊµÅË°åÊñπÊ≥ïÊòØ‰∏ªÊàêÂàÜÂàÜÊûê (PCA) „ÄÇPCA Ê∂âÂèäÂ∞ÜÈ´òÁª¥Êï∞ÊçÆÔºà‰æãÂ¶Ç 3D ÔºâËΩ¨Êç¢‰∏∫ËæÉÂ∞èÁöÑÁ©∫Èó¥Ôºà‰æãÂ¶Ç 2D Ôºâ„ÄÇ ‚ÄúÊµÅÂΩ¢ÂÅáËÆæ‚ÄùÊèêÂá∫È´òÁª¥Êï∞ÊçÆÈõÜ‰Ωç‰∫é‰ΩéÁª¥ÊµÅÂΩ¢‰∏äÔºåËÆ∏Â§öÈôçÁª¥ÊäÄÊúØÈÉΩÂü∫‰∫éËøô‰∏ÄÂÅáËÆæÔºå‰ªéËÄå‰∫ßÁîü‰∫ÜÊµÅÂΩ¢Â≠¶‰π†ÂíåÊµÅÂΩ¢Ê≠£ÂàôÂåñÈ¢ÜÂüü„ÄÇ</em></p>
</blockquote>
<h3 id="Ëá™Â≠¶‰π†--self-learning">Ëá™Â≠¶‰π† ‚Äî Self-Learning
</h3><blockquote>
<p>Self-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA). It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion. The self-learning algorithm updates a memory matrix \( W =\|w(a,s)\| \) such that in each iteration executes the following machine learning routine:</p>
<p><em>Ëá™Â≠¶‰π†ÊòØ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†ËåÉÂºèÔºå‰∫é1982Âπ¥‰∏é‰∏ÄÁßçËÉΩÂ§üËá™ÊàëÂ≠¶‰π†ÁöÑÁ•ûÁªèÁΩëÁªú‰∏ÄËµ∑Ë¢´ÂºïÂÖ•ÔºåËØ•Á•ûÁªèÁΩëÁªúË¢´Áß∞‰∏∫‰∫§ÂèâÂºÄÂÖ≥Ëá™ÈÄÇÂ∫îÈòµÂàó (CAA) „ÄÇËøôÊòØ‰∏ÄÁßçÊó†ÈúÄÂ§ñÈÉ®Â•ñÂä±ÂíåÂ§ñÈÉ®ÊïôÂ∏àÊåáÂØºÁöÑÂ≠¶‰π†ÊñπÂºè„ÄÇ CAA ÁöÑËá™Â≠¶‰π†ÁÆóÊ≥ïÈááÁî®‰∫§ÂèâÊñπÂºèËÆ°ÁÆóÂÖ≥‰∫éÂä®‰ΩúÂíåÂÖ≥‰∫éÂêéÊûúÊÉÖÂÜµÁöÑÊÉÖÊÑüÔºàÊÉÖÁª™ÔºâÂÜ≥Á≠ñ„ÄÇÁ≥ªÁªüÁî±ËÆ§Áü•ÂíåÊÉÖÊÑü‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®È©±Âä®„ÄÇËá™Â≠¶‰π†ÁÆóÊ≥ïÊõ¥Êñ∞‰∏Ä‰∏™ËÆ∞ÂøÜÁü©Èòµ \( W =\|w(a,s)\| \) Ôºå‰ΩøÂæóÂú®ÊØèÊ¨°Ëø≠‰ª£‰∏≠ÊâßË°å‰ª•‰∏ãÊú∫Âô®Â≠¶‰π†ÊµÅÁ®ãÔºö</em></p>
<ul>
<li>in situation \( s \) perform action \( a \)
<ul>
<li><em>Âú®ÊÉÖÂÜµ \( s \) ‰∏ãÈááÂèñË°åÂä® \( a \)</em></li>
</ul>
</li>
<li>receive a consequence situation \( s' \)
<ul>
<li><em>Èù¢‰∏¥ÂêéÊûú \( s' \)</em></li>
</ul>
</li>
<li>compute emotion of being in the consequence situation \( v(s') \)
<ul>
<li><em>ËÆ°ÁÆóÂ§Ñ‰∫éÂêéÊûúÊÉÖÂ¢É‰∏≠ÁöÑÊÉÖÁª™ \( v(s') \)</em></li>
</ul>
</li>
<li>update crossbar memory \( w'(a,s) = w(a,s) + v(s') \)
<ul>
<li><em>Êõ¥Êñ∞‰∫§ÂèâÂºÄÂÖ≥ÁöÑËÆ∞ÂøÜ \( w'(a,s) = w(a,s) + v(s') \)</em></li>
</ul>
</li>
</ul>
<p>It is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.</p>
<p><em>ËøôÊòØ‰∏Ä‰∏™Âè™ÊúâÂçï‰∏ÄËæìÂÖ•ÔºàÊÉÖÂÜµÔºâÂíåÂçï‰∏ÄËæìÂá∫ÔºàË°åÂä®ÊàñË°å‰∏∫Ôºâ \( a \) ÁöÑÁ≥ªÁªü„ÄÇÁéØÂ¢ÉÊó¢Ê≤°ÊúâÁã¨Á´ãÁöÑÂº∫ÂåñËæìÂÖ•Ôºå‰πüÊ≤°ÊúâÊù•Ëá™ÁéØÂ¢ÉÁöÑÂª∫ËÆÆËæìÂÖ•„ÄÇÂèçÂêë‰º†Êí≠ÁöÑ‰ª∑ÂÄºÔºàÊ¨°Á∫ßÂº∫ÂåñÔºâÊòØÂØπÂêéÊûúÊÉÖÂÜµÁöÑÊÉÖÁª™„ÄÇ CAA Â≠òÂú®‰∫é‰∏§‰∏™ÁéØÂ¢É‰∏≠Ôºå‰∏Ä‰∏™ÊòØË°å‰∏∫ÁéØÂ¢ÉÔºå CAA Âú®ÂÖ∂‰∏≠Ë°®Áé∞ÔºåÂè¶‰∏Ä‰∏™ÊòØÈÅó‰º†ÁéØÂ¢ÉÔºå CAA ‰ªÖÂú®‰∏ÄÊ¨°‰∏îÊúÄÂàù‰ªé‰∏≠Êé•Êî∂ÂÖ≥‰∫éÂ∞ÜÂú®Ë°å‰∏∫ÁéØÂ¢É‰∏≠ÈÅáÂà∞ÁöÑÊÉÖÂÜµÁöÑÂàùÂßãÊÉÖÁª™„ÄÇ‰ªéÈÅó‰º†ÁéØÂ¢É‰∏≠Êé•Êî∂Âü∫Âõ†ÔºàÁâ©ÁßçÔºâÂêëÈáèÂêéÔºå CAA Â≠¶‰π†‰∏ÄÁßçÂØªÊ±ÇÁõÆÊ†áÁöÑË°å‰∏∫ÔºåÂú®‰∏Ä‰∏™ÂåÖÂê´Êó¢ÊúâÂê∏ÂºïÂäõÂèàÊúâÊéíÊñ•ÂäõÁöÑÊÉÖÂÜµÁöÑÁéØÂ¢É‰∏≠„ÄÇ</em></p>
</blockquote>
<h2 id="Ê®°Âûã">Ê®°Âûã
</h2><blockquote>
<p>A machine learning model is a type of mathematical model that, after being &ldquo;trained&rdquo; on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model&rsquo;s internal parameters to minimize errors in its predictions. By extension, the term &ldquo;model&rdquo; can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.</p>
<p><em>Êú∫Âô®Â≠¶‰π†Ê®°ÂûãÊòØ‰∏ÄÁßçÊï∞Â≠¶Ê®°ÂûãÔºåÂú®ÂØπÁªôÂÆöÊï∞ÊçÆÈõÜËøõË°å‚ÄúËÆ≠ÁªÉ‚ÄùÂêéÔºåÂèØ‰ª•Áî®‰∫éÂØπÊñ∞Êï∞ÊçÆËøõË°åÈ¢ÑÊµãÊàñÂàÜÁ±ª„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÂ≠¶‰π†ÁÆóÊ≥ï‰ºöÈÄêÊ¨°Ë∞ÉÊï¥Ê®°ÂûãÂÜÖÈÉ®ÂèÇÊï∞Ôºå‰ª•ÊúÄÂ∞èÂåñÂÖ∂È¢ÑÊµã‰∏≠ÁöÑËØØÂ∑Æ„ÄÇÂõ†Ê≠§Ôºå‚ÄúÊ®°Âûã‚Äù‰∏ÄËØçÂèØ‰ª•Êåá‰ª£ÁâπÂÆöÊ®°ÂûãÂèäÂÖ∂Áõ∏ÂÖ≥Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂ§ö‰∏™Â±ÇÊ¨°ÔºåÁõ¥Ëá≥Êåá‰ª£ÂÆåÂÖ®ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÂèäÂÖ∂ÊâÄÊúâÂÜÖÈÉ®ÂèÇÊï∞ÁöÑË∞ÉÊï¥„ÄÇ</em></p>
<p>Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.</p>
<p>Êú∫Âô®Â≠¶‰π†Á≥ªÁªü‰∏≠‰ΩøÁî®‰∫ÜÂêÑÁßçÁ±ªÂûãÁöÑÊ®°ÂûãÔºå‰∏∫‰ªªÂä°ÈÄâÊã©ÊúÄ‰Ω≥Ê®°ÂûãÁß∞‰∏∫Ê®°ÂûãÈÄâÊã©„ÄÇ</p>
</blockquote>
<h3 id="‰∫∫Â∑•Á•ûÁªèÁΩëÁªú--artificial-neural-network-ann">‰∫∫Â∑•Á•ûÁªèÁΩëÁªú ‚Äî Artificial Neural Network (ANN)
</h3><blockquote>
<p>Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems &ldquo;learn&rdquo; to perform tasks by considering examples, generally without being programmed with any task-specific rules.</p>
<p><em>‰∫∫Â∑•Á•ûÁªèÁΩëÁªú (ANNs) ÊàñÁß∞ËøûÊé•‰∏ª‰πâÁ≥ªÁªüÔºåÊòØ‰∏ÄÁßçÂèóÁîüÁâ©Á•ûÁªèÁΩëÁªúÂêØÂèëÁöÑËÆ°ÁÆóÁ≥ªÁªüÔºåÂêéËÄÖÊûÑÊàê‰∫ÜÂä®Áâ©Â§ßËÑëÁöÑÂäüËÉΩ„ÄÇËøôÁßçÁ≥ªÁªüÈÄöÂ∏∏ÈÄöËøáËÄÉËôëÁ§∫‰æãÊù•‚ÄúÂ≠¶‰π†‚ÄùÊâßË°å‰ªªÂä°ÔºåÈÄöÂ∏∏Êó†ÈúÄÊåâÁÖßÁâπÂÆö‰ªªÂä°ÁöÑËßÑÂàôËøõË°åÁºñÁ®ã„ÄÇ</em></p>
<p>An ANN is a model based on a collection of connected units or nodes called &ldquo;artificial neurons&rdquo;, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a &ldquo;signal&rdquo;, from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called &ldquo;edges&rdquo;. Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.</p>
<p><em>ANN ÊòØ‰∏ÄÁßçÂü∫‰∫éËøûÊé•Âú®‰∏ÄËµ∑ÁöÑÂçïÂÖÉÊàñËäÇÁÇπÔºàÁß∞‰∏∫‚Äú‰∫∫Â∑•Á•ûÁªèÂÖÉ‚ÄùÔºâÁöÑÊ®°ÂûãÔºåÂÆÉÂ§ßËá¥Ê®°ÊãüÁîüÁâ©Â§ßËÑë‰∏≠ÁöÑÁ•ûÁªèÂÖÉ„ÄÇÊØè‰∏™ËøûÊé•ÔºàÁ±ª‰ºº‰∫éÁîüÁâ©Â§ßËÑë‰∏≠ÁöÑÁ™ÅËß¶ÔºâÈÉΩÂèØ‰ª•‰ªé‰∏Ä‰∏™‰∫∫Â∑•Á•ûÁªèÂÖÉÂêëÂè¶‰∏Ä‰∏™‰∫∫Â∑•Á•ûÁªèÂÖÉ‰º†Ëæì‰ø°ÊÅØÔºåÂç≥‚Äú‰ø°Âè∑‚Äù„ÄÇÊé•Êî∂‰ø°Âè∑ÁöÑ‰∫∫Â∑•Á•ûÁªèÂÖÉÂèØ‰ª•ÂØπ‰ø°Âè∑ËøõË°åÂ§ÑÁêÜÔºåÁÑ∂ÂêéÂêë‰∏éÂÖ∂ËøûÊé•ÁöÑÂÖ∂‰ªñ‰∫∫Â∑•Á•ûÁªèÂÖÉÂèëÈÄÅ‰ø°Âè∑„ÄÇÂú®Â∏∏ËßÅÁöÑ ANN ÂÆûÁé∞‰∏≠Ôºå‰∫∫Â∑•Á•ûÁªèÂÖÉ‰πãÈó¥ÁöÑËøûÊé•‰πãÈó¥ÁöÑ‰ø°Âè∑ÊòØ‰∏Ä‰∏™ÂÆûÊï∞ÔºåÊØè‰∏™‰∫∫Â∑•Á•ûÁªèÂÖÉÁöÑËæìÂá∫ÊòØÂÖ∂ËæìÂÖ•ÊÄªÂíåÁöÑÊüê‰∏™ÈùûÁ∫øÊÄßÂáΩÊï∞„ÄÇ‰∫∫Â∑•Á•ûÁªèÂÖÉÂíåËøûÊé•‰πãÈó¥ÁöÑËæπÁºòÈÄöÂ∏∏Êúâ‰∏Ä‰∏™ÊùÉÈáçÔºåÈöèÁùÄÂ≠¶‰π†ÁöÑËøõË°åËÄåË∞ÉÊï¥„ÄÇÊùÉÈáç‰ºöÂ¢ûÂä†ÊàñÂáèÂ∞ëËøûÊé•Â§Ñ‰ø°Âè∑ÁöÑÂº∫Â∫¶„ÄÇ‰∫∫Â∑•Á•ûÁªèÂÖÉÂèØËÉΩÊúâ‰∏Ä‰∏™ÈòàÂÄºÔºåÂè™ÊúâÂΩìÊÄª‰ø°Âè∑Ë∂ÖËøáËØ•ÈòàÂÄºÊó∂Êâç‰ºöÂèëÈÄÅ‰ø°Âè∑„ÄÇÈÄöÂ∏∏Ôºå‰∫∫Â∑•Á•ûÁªèÂÖÉ‰ºöÁªÑÂêàÊàê‰∏çÂêåÁöÑÂ±Ç„ÄÇ‰∏çÂêåÁöÑÂ±ÇÂèØËÉΩÂØπÂÖ∂ËæìÂÖ•ÊâßË°å‰∏çÂêåÁöÑÂèòÊç¢„ÄÇ‰ø°Âè∑‰ªéÁ¨¨‰∏ÄÂ±ÇÔºàËæìÂÖ•Â±ÇÔºâ‰º†ÈÄíÂà∞ÊúÄÂêé‰∏ÄÂ±ÇÔºàËæìÂá∫Â±ÇÔºâÔºåÂèØËÉΩÈúÄË¶ÅÂú®ÂêÑÂ±Ç‰πãÈó¥Â§öÊ¨°Á©øÊ¢≠„ÄÇ</em></p>
<p>The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.</p>
<p><em>ANN ÊñπÊ≥ïÁöÑÂéüÂßãÁõÆÊ†áÊòØÂÉè‰∫∫ËÑë‰∏ÄÊ†∑Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇÁÑ∂ËÄåÔºåÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÔºå‰∫∫‰ª¨ÁöÑÂÖ≥Ê≥®ÁÇπËΩ¨ÂêëÊâßË°åÁâπÂÆöÁöÑ‰ªªÂä°ÔºåÂØºËá¥ÂÅèÁ¶ª‰∫ÜÁîüÁâ©Â≠¶„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÁ•ûÁªèÁΩëÁªúÂ∑≤Ë¢´Â∫îÁî®‰∫éÂêÑÁßç‰ªªÂä°ÔºåÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅËØ≠Èü≥ËØÜÂà´„ÄÅÊú∫Âô®ÁøªËØë„ÄÅÁ§æ‰∫§ÁΩëÁªúËøáÊª§„ÄÅÊ£ãÁõòÂíåËßÜÈ¢ëÊ∏∏Êàè‰ª•ÂèäÂåªÂ≠¶ËØäÊñ≠„ÄÇ</em></p>
<p>Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.</p>
<p><em>Ê∑±Â∫¶Â≠¶‰π†ÊòØ‰∏ÄÁßçÂú®‰∫∫Â∑•Á•ûÁªèÁΩëÁªú‰∏≠ÂåÖÂê´Â§ö‰∏™ÈöêËóèÂ±ÇÁöÑÊñπÊ≥ï„ÄÇËøôÁßçÊñπÊ≥ïËØïÂõæÊ®°Êãü‰∫∫Á±ªÂ§ßËÑëÂ∞ÜÂÖâÂíåÂ£∞Èü≥ËΩ¨Êç¢‰∏∫ËßÜËßâÂíåÂê¨ËßâÁöÑÊñπÂºè„ÄÇÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰∏Ä‰∫õÊàêÂäüÂ∫îÁî®ÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâÂíåËØ≠Èü≥ËØÜÂà´„ÄÇ</em></p>
</blockquote>
<h3 id="ÂÜ≥Á≠ñÊ†ë--decision-tree">ÂÜ≥Á≠ñÊ†ë ‚Äî Decision Tree
</h3><blockquote>
<p>Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item&rsquo;s target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.</p>
<p><em>ÂÜ≥Á≠ñÊ†ëÂ≠¶‰π†‰ΩøÁî®ÂÜ≥Á≠ñÊ†ë‰Ωú‰∏∫È¢ÑÊµãÊ®°ÂûãÔºå‰ªéÂÖ≥‰∫éÊüê‰∏™È°πÁõÆÔºà‰ª•Ê†ëÊûùË°®Á§∫ÔºâÁöÑËßÇÂØüÁªìÊûúÂá∫ÂèëÔºåÊé®Êñ≠Âá∫ËØ•È°πÁõÆÁöÑÁõÆÊ†áÂÄºÔºà‰ª•Ê†ëÂè∂Ë°®Á§∫Ôºâ„ÄÇÂÆÉÊòØÁªüËÆ°Â≠¶„ÄÅÊï∞ÊçÆÊåñÊéòÂíåÊú∫Âô®Â≠¶‰π†‰∏≠‰ΩøÁî®ÁöÑÈ¢ÑÊµãÂª∫Ê®°ÊñπÊ≥ï‰πã‰∏Ä„ÄÇÁõÆÊ†áÂèòÈáèÂèØ‰ª•ÂèñÁ¶ªÊï£ÈõÜÂêàÂÄºÁöÑÊ†ëÊ®°ÂûãÁß∞‰∏∫ÂàÜÁ±ªÊ†ëÔºõÂú®Ëøô‰∫õÊ†ëÁªìÊûÑ‰∏≠ÔºåÂè∂Â≠ê‰ª£Ë°®Á±ªÊ†áÁ≠æÔºåÊ†ëÊûù‰ª£Ë°®ÂØºËá¥Ëøô‰∫õÁ±ªÊ†áÁ≠æÁöÑÁâπÂæÅÁöÑ‰∫§ÈõÜ„ÄÇÁõÆÊ†áÂèòÈáèÂèØ‰ª•ÂèñËøûÁª≠ÂÄºÔºàÈÄöÂ∏∏ÊòØÂÆûÊï∞ÔºâÁöÑÂÜ≥Á≠ñÊ†ëÁß∞‰∏∫ÂõûÂΩíÊ†ë„ÄÇÂú®ÂÜ≥Á≠ñÂàÜÊûê‰∏≠ÔºåÂÜ≥Á≠ñÊ†ëÂèØ‰ª•Áî®‰∫éÂèØËßÜÂåñÂíåÊòéÁ°ÆÂú∞Ë°®Á§∫ÂÜ≥Á≠ñÂíåÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇÂú®Êï∞ÊçÆÊåñÊéò‰∏≠ÔºåÂÜ≥Á≠ñÊ†ëÊèèËø∞Êï∞ÊçÆÔºå‰ΩÜÁîüÊàêÁöÑÂàÜÁ±ªÊ†ëÂèØ‰ª•‰Ωú‰∏∫ÂÜ≥Á≠ñÁöÑËæìÂÖ•„ÄÇ</em></p>
</blockquote>
<h3 id="ÊîØÊåÅÂêëÈáèÊú∫--support-vector-machine-svm">ÊîØÊåÅÂêëÈáèÊú∫ ‚Äî Support-Vector Machine (SVM)
</h3><blockquote>
<p>Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category. An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.</p>
<p><em>ÊîØÊåÅÂêëÈáèÊú∫ (SVM) ÂèàÁß∞‰∏∫ÊîØÊåÅÂêëÈáèÁΩëÁªúÔºåÊòØ‰∏ÄÁßçÁî®‰∫éÂàÜÁ±ªÂíåÂõûÂΩíÁöÑÁõ∏ÂÖ≥ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÁöÑÈõÜÂêà„ÄÇÁªôÂÆö‰∏ÄÁªÑÂ∏¶ÊúâÊ†áËÆ∞ÁöÑËÆ≠ÁªÉÁ§∫‰æãÔºåÊØè‰∏™Á§∫‰æãÈÉΩË¢´Ê†áËÆ∞‰∏∫Â±û‰∫é‰∏§‰∏™Á±ªÂà´‰∏≠ÁöÑ‰∏Ä‰∏™ÔºåSVM ËÆ≠ÁªÉÁÆóÊ≥ï‰ºöÊûÑÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºåÁî®‰∫éÈ¢ÑÊµãÊñ∞Á§∫‰æãÂ±û‰∫éÂì™‰∏™Á±ªÂà´„ÄÇSVMËÆ≠ÁªÉÁÆóÊ≥ïÊòØ‰∏ÄÁßçÈùûÊ¶ÇÁéáÁöÑ‰∫åÂÖÉÁ∫øÊÄßÂàÜÁ±ªÂô®ÔºåÂ∞ΩÁÆ°Â≠òÂú®ËØ∏Â¶Ç Platt Áº©Êîæ‰πãÁ±ªÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Â∞Ü SVM Â∫îÁî®‰∫éÊ¶ÇÁéáÂàÜÁ±ªÁéØÂ¢É‰∏≠„ÄÇÈô§‰∫ÜËøõË°åÁ∫øÊÄßÂàÜÁ±ªÂ§ñÔºå SVM ËøòÂèØ‰ª•È´òÊïàÂú∞‰ΩøÁî®ÊâÄË∞ìÁöÑ‚ÄúÊ†∏ÊäÄÂ∑ß‚ÄùËøõË°åÈùûÁ∫øÊÄßÂàÜÁ±ªÔºåÂ∞ÜËæìÂÖ•Êï∞ÊçÆÈöêÂºèÊò†Â∞ÑÂà∞È´òÁª¥ÁâπÂæÅÁ©∫Èó¥„ÄÇ</em></p>
</blockquote>
<h3 id="ÂõûÂΩíÂàÜÊûê--regression-analysis">ÂõûÂΩíÂàÜÊûê ‚Äî Regression Analysis
</h3><blockquote>
<p>Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.</p>
<p><em>ÂõûÂΩíÂàÜÊûêÊòØ‰∏ÄÁßçÂåÖÂê´Â§öÁßçÁªüËÆ°ÊñπÊ≥ïÁöÑÂ∑•ÂÖ∑ÔºåÁî®‰∫é‰º∞ËÆ°ËæìÂÖ•ÂèòÈáè‰∏éÂÖ∂Áõ∏ÂÖ≥ÁâπÂæÅ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂÖ∂ÊúÄÂ∏∏ËßÅÁöÑÂΩ¢ÂºèÊòØÁ∫øÊÄßÂõûÂΩíÔºåÂç≥Ê†πÊçÆËØ∏Â¶ÇÊôÆÈÄöÊúÄÂ∞è‰∫å‰πòÊ≥ïÁ≠âÊï∞Â≠¶ÂáÜÂàôÔºåÁªòÂà∂‰∏ÄÊù°Áõ¥Á∫øÊù•ÊúÄ‰Ω≥ÊãüÂêàÁªôÂÆöÁöÑÊï∞ÊçÆ„ÄÇÂêéËÄÖÈÄöÂ∏∏ÈÄöËøáÊ≠£ÂàôÂåñÊñπÊ≥ïËøõË°åÊâ©Â±ïÔºå‰ª•ÂáèÂ∞ëËøáÊãüÂêàÂíåÂÅèÂ∑ÆÔºå‰æãÂ¶ÇÂ≤≠ÂõûÂΩí„ÄÇÂΩìÂ§ÑÁêÜÈùûÁ∫øÊÄßÈóÆÈ¢òÊó∂ÔºåÂ∏∏Áî®ÁöÑÊ®°ÂûãÂåÖÊã¨Â§öÈ°πÂºèÂõûÂΩíÔºà‰æãÂ¶ÇÔºåÁî®‰∫éÂú® Microsoft Excel ‰∏≠ÁªòÂà∂Ë∂ãÂäøÁ∫øÔºâ„ÄÅÈÄªËæëÂõûÂΩíÔºàÈÄöÂ∏∏Áî®‰∫éÁªüËÆ°ÂàÜÁ±ªÔºâÔºåÁîöËá≥Ê†∏ÂõûÂΩíÔºåÈÄöËøáÂà©Áî®Ê†∏ÊäÄÂ∑ßÂ∞ÜËæìÂÖ•ÂèòÈáèÈöêÂºèÊò†Â∞ÑÂà∞Êõ¥È´òÁª¥Á©∫Èó¥Êù•ÂºïÂÖ•ÈùûÁ∫øÊÄß„ÄÇ</em></p>
</blockquote>
<h3 id="bayes-ÁΩëÁªú--bayesian-network">Bayes ÁΩëÁªú ‚Äî Bayesian Network
</h3><blockquote>
<p>A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.</p>
<p><em>Bayes ÁΩëÁªúÔºà‰πüÁß∞‰∏∫‰ø°ÂøµÁΩëÁªúÊàñÊúâÂêëÊó†ÁéØÂõæÊ®°ÂûãÔºâÊòØ‰∏ÄÁßçÊ¶ÇÁéáÂõæÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÊúâÂêëÊó†ÁéØÂõæ (DAG) Êù•Ë°®Á§∫‰∏ÄÁªÑÈöèÊú∫ÂèòÈáèÂèäÂÖ∂Êù°‰ª∂Áã¨Á´ãÊÄß„ÄÇ‰æãÂ¶ÇÔºå Bayes ÁΩëÁªúÂèØ‰ª•Ë°®Á§∫ÁñæÁóÖÂíåÁóáÁä∂‰πãÈó¥ÁöÑÊ¶ÇÁéáÂÖ≥Á≥ª„ÄÇÁªôÂÆöÁóáÁä∂ÔºåËØ•ÁΩëÁªúÂèØ‰ª•ËÆ°ÁÆóÂêÑÁßçÁñæÁóÖÂ≠òÂú®ÁöÑÊ¶ÇÁéá„ÄÇÂ≠òÂú®È´òÊïàÁöÑÁÆóÊ≥ïÂèØ‰ª•ËøõË°åÊé®ÁêÜÂíåÂ≠¶‰π†„ÄÇË°®Á§∫ÂíåËß£ÂÜ≥‰∏çÁ°ÆÂÆöÊÄßÊù°‰ª∂‰∏ãÂÜ≥Á≠ñÈóÆÈ¢òÁöÑ Bayes ÁΩëÁªúÁöÑ‰∏ÄËà¨ÂåñÂΩ¢ÂºèÁß∞‰∏∫ÂΩ±ÂìçÂõæ„ÄÇ</em></p>
</blockquote>
<h3 id="gauss-ËøáÁ®ã--gaussian-process">Gauss ËøáÁ®ã ‚Äî Gaussian Process
</h3><blockquote>
<p>A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.</p>
<p><em>Gauss ËøáÁ®ãÊòØ‰∏ÄÁßçÈöèÊú∫ËøáÁ®ãÔºåÂÖ∂‰∏≠ËøáÁ®ãÁöÑ‰ªªÊÑèÊúâÈôêÈõÜÂêàÁöÑÈöèÊú∫ÂèòÈáèÈÉΩÊúâÂ§öÁª¥Ê≠£ÊÄÅÂàÜÂ∏É„ÄÇÂÆÉ‰æùËµñ‰∫é‰∏Ä‰∏™È¢ÑÂÖàÂÆö‰πâÁöÑÂçèÊñπÂ∑ÆÂáΩÊï∞ÔºàÊàñÊ†∏ÂáΩÊï∞ÔºâÔºåËØ•ÂáΩÊï∞Ê†πÊçÆÁÇπÁöÑ‰ΩçÁΩÆÊ®°ÂûãÁÇπÂØπ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ</em>
Given a set of observed points, or input‚Äìoutput examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.</p>
<p><em>ÁªôÂÆö‰∏ÄÁªÑËßÇÂØüÁÇπÊàñËæìÂÖ•-ËæìÂá∫Á§∫‰æãÔºåÂèØ‰ª•ÈÄöËøáËßÇÂØüËøô‰∫õÁÇπÂèäÂÖ∂‰∏éÊñ∞„ÄÅÊú™ËßÇÂØüÁÇπ‰πãÈó¥ÁöÑÂçèÊñπÂ∑ÆÊù•Áõ¥Êé•ËÆ°ÁÆóÊñ∞ÁÇπËæìÂá∫ÔºàÂç≥Êú™ËßÇÂØüÁÇπÁöÑËæìÂá∫ÔºâÁöÑÂàÜÂ∏É„ÄÇ</em></p>
<p>Gaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.</p>
<p><em>Gauss ËøáÁ®ãÊòØ Bayes ‰ºòÂåñ‰∏≠Â∏∏Áî®ÁöÑË∂ÖÂèÇÊï∞‰ºòÂåñÊõø‰ª£Ê®°Âûã„ÄÇ</em></p>
</blockquote>
<h3 id="ÈÅó‰º†ÁÆóÊ≥ï--genetic-algorithm">ÈÅó‰º†ÁÆóÊ≥ï ‚Äî Genetic Algorithm
</h3><blockquote>
<p>A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s. Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.</p>
<p><em>ÈÅó‰º†ÁÆóÊ≥ï (GA) ÊòØ‰∏ÄÁßç‰ªøÁÖßËá™ÁÑ∂ÈÄâÊã©ËøáÁ®ãÁöÑÊêúÁ¥¢ÁÆóÊ≥ïÂíåÂêØÂèëÂºèÊäÄÊúØÔºåÂÆÉ‰ΩøÁî®Á™ÅÂèòÂíå‰∫§ÂèâÁ≠âÊñπÊ≥ïÊù•ÁîüÊàêÊñ∞ÁöÑÂü∫Âõ†ÂûãÔºå‰ª•ÊúüÊâæÂà∞ÁªôÂÆöÈóÆÈ¢òÁöÑËâØÂ•ΩËß£ÂÜ≥ÊñπÊ°à„ÄÇÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüüÔºåÈÅó‰º†ÁÆóÊ≥ïÂú® 20 ‰∏ñÁ∫™ 80 Âπ¥‰ª£Âíå 90 Âπ¥‰ª£ÂæóÂà∞‰∫ÜÂ∫îÁî®„ÄÇÁõ∏ÂèçÔºåÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÂ∑≤Ë¢´Áî®‰∫éÊîπËøõÈÅó‰º†ÂíåËøõÂåñÁÆóÊ≥ïÁöÑÊÄßËÉΩ„ÄÇ</em></p>
</blockquote>
<h3 id="‰ø°ÂøµÂáΩÊï∞--belief-function">‰ø°ÂøµÂáΩÊï∞ ‚Äî Belief Function
</h3><blockquote>
<p>The theory of belief functions, also referred to as evidence theory or Dempster‚ÄìShafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g., Dempster&rsquo;s rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner&rsquo;s decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving. However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.</p>
<p><em>‰ø°ÂøµÂáΩÊï∞ÁêÜËÆ∫ÔºåÂèàÁß∞‰∏∫ËØÅÊçÆÁêÜËÆ∫Êàñ Dempster‚ÄìShafer ÁêÜËÆ∫ÔºåÊòØ‰∏ÄÁßçÂ§ÑÁêÜ‰∏çÁ°ÆÂÆöÊÄßÁöÑÈÄöÁî®Ê°ÜÊû∂Ôºå‰∏éÊ¶ÇÁéá„ÄÅÂèØËÉΩÊÄßÂíå‰∏çÁ≤æÁ°ÆÊ¶ÇÁéáÁêÜËÆ∫Á≠âÂÖ∂‰ªñÊ°ÜÊû∂Â≠òÂú®ËÅîÁ≥ª„ÄÇËøô‰∫õÁêÜËÆ∫Ê°ÜÊû∂ÂèØ‰ª•Ë¢´Áúã‰ΩúÊòØ‰∏ÄÁßçÂ≠¶‰π†Âô®ÔºåÂÖ∑ÊúâÂ∞ÜËØÅÊçÆÁªÑÂêàÔºà‰æãÂ¶ÇÔºå Dempster ÁªÑÂêàËßÑÂàôÔºâÁöÑÁ±ª‰ººÁâπÊÄßÔºåÂ∞±ÂÉèÂú®Âü∫‰∫é pmf ÁöÑ Bayes ÊñπÊ≥ï‰∏≠‰ºöÂ∞ÜÊ¶ÇÁéáËøõË°åÁªÑÂêà‰∏ÄÊ†∑„ÄÇÁÑ∂ËÄåÔºå‰∏é Bayes ÊñπÊ≥ïÁõ∏ÊØîÔºå‰ø°ÂøµÂáΩÊï∞ÊñπÊ≥ïÂú®Á∫≥ÂÖ•Êó†Áü•Âíå‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÊó∂Â≠òÂú®ËÆ∏Â§öÂ±ÄÈôêÊÄß„ÄÇÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüü‰∏≠ÂÆûÁé∞ÁöÑËøô‰∫õ‰ø°ÂøµÂáΩÊï∞ÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®ÂêÑÁßçÈõÜÊàêÊñπÊ≥ïÁöÑËûçÂêàÁ≠ñÁï•Ôºå‰ª•Êõ¥Â•ΩÂú∞Â§ÑÁêÜÂ≠¶‰π†Âô®ÁöÑÂÜ≥Á≠ñËæπÁïå„ÄÅ‰ΩéÊ†∑Êú¨ÈáèÂíåÊ®°Á≥äÁ±ªÈóÆÈ¢òÔºåËÄåËøô‰∫õÈóÆÈ¢òÈÄöÂ∏∏ÊòØ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÈöæ‰ª•Ëß£ÂÜ≥ÁöÑ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÁÆóÊ≥ïÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂèñÂÜ≥‰∫éÂëΩÈ¢òÔºàÁ±ªÔºâÁöÑÊï∞ÈáèÔºå‰∏éÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØËÉΩ‰ºöÂØºËá¥Êõ¥È´òÁöÑËÆ°ÁÆóÊó∂Èó¥„ÄÇ</em></p>
</blockquote>
<h3 id="ËÆ≠ÁªÉÊ®°Âûã">ËÆ≠ÁªÉÊ®°Âûã
</h3><blockquote>
<p>Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.</p>
<p><em>ÈÄöÂ∏∏Êù•ËØ¥ÔºåÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÈúÄË¶ÅÂ§ßÈáèÁöÑÂèØÈù†Êï∞ÊçÆÊù•ËøõË°åÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇÂú®ËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÊó∂ÔºåÊú∫Âô®Â≠¶‰π†Â∑•Á®ãÂ∏àÈúÄË¶ÅÈíàÂØπÂπ∂Êî∂ÈõÜÂ§ßÈáèÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÊï∞ÊçÆÊ†∑Êú¨„ÄÇËÆ≠ÁªÉÈõÜÁöÑÊï∞ÊçÆÂèØ‰ª•ÊòØÂ§öÁßçÂ§öÊ†∑ÁöÑÔºåÊØîÂ¶ÇÊñáÊú¨ËØ≠ÊñôÂ∫ì„ÄÅÂõæÂÉèÈõÜÂêà„ÄÅ‰º†ÊÑüÂô®Êï∞ÊçÆÔºå‰ª•ÂèäÊù•Ëá™ÊúçÂä°‰∏≠Âçï‰∏™Áî®Êà∑ÁöÑÊï∞ÊçÆ„ÄÇÂú®ËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÊó∂ÔºåÈúÄË¶ÅË≠¶ÊÉïËøáÂ∫¶ÊãüÂêàÁöÑÈóÆÈ¢ò„ÄÇÁî±Â∏¶ÊúâÂÅèËßÅÊàñÊú™ÁªèËØÑ‰º∞ÁöÑÊï∞ÊçÆËÆ≠ÁªÉÂæóÂà∞ÁöÑÊ®°ÂûãÂèØËÉΩ‰ºöÂØºËá¥È¢ÑÊµãÂÅèÊñúÊàñ‰∏çÂèØÊé•Âèó„ÄÇÂ∏¶ÊúâÂÅèËßÅÁöÑÊ®°ÂûãÂèØËÉΩ‰ºöÂØºËá¥‰∏çÂà©ÂêéÊûúÔºå‰ªéËÄåËøõ‰∏ÄÊ≠•Âä†ÂâßÂØπÁ§æ‰ºöÊàñÁõÆÊ†áÁöÑË¥üÈù¢ÂΩ±Âìç„ÄÇÁÆóÊ≥ïÂÅèËßÅÂèØËÉΩÊòØÁî±‰∫éÊï∞ÊçÆÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ê≤°ÊúâÂæóÂà∞ÂÖÖÂàÜÂáÜÂ§áËÄå‰∫ßÁîüÁöÑÊΩúÂú®ÁªìÊûú„ÄÇÊú∫Âô®Â≠¶‰π†‰º¶ÁêÜÂ≠¶Ê≠£Âú®Êàê‰∏∫‰∏ÄÈó®Â≠¶ÁßëÔºåÂπ∂‰∏îË∂äÊù•Ë∂äÂèóÂà∞Êú∫Âô®Â≠¶‰π†Â∑•Á®ãÂõ¢ÈòüÁöÑÈáçËßÜ„ÄÇ</em></p>
</blockquote>
<h3 id="ËÅîÈÇ¶Â≠¶‰π†">ËÅîÈÇ¶Â≠¶‰π†
</h3><blockquote>
<p>Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users&rsquo; privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users&rsquo; mobile phones without having to send individual searches back to Google.</p>
<p><em>ËÅîÈÇ¶Â≠¶‰π†ÊòØ‰∏ÄÁßçÈÄÇÂ∫îÊÄßÂàÜÂ∏ÉÂºè‰∫∫Â∑•Êô∫ËÉΩÔºåÁî®‰∫éÂú®‰∏çÂ∞ÜÁî®Êà∑Êï∞ÊçÆÂèëÈÄÅÂà∞ÈõÜ‰∏≠ÂºèÊúçÂä°Âô®ÁöÑÊÉÖÂÜµ‰∏ãËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºå‰ªéËÄå‰øùÊä§Áî®Êà∑ÁöÑÈöêÁßÅ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÂ∞ÜËÆ≠ÁªÉËøáÁ®ãÂàÜÊï£Âà∞Â§ö‰∏™ËÆæÂ§á‰∏äÔºåËøòÂèØ‰ª•ÊèêÈ´òÊïàÁéá„ÄÇ‰æãÂ¶ÇÔºå Gboard ‰ΩøÁî®ËÅîÈÇ¶Êú∫Âô®Â≠¶‰π†Âú®Áî®Êà∑ÁöÑÁßªÂä®ËÆæÂ§á‰∏äËÆ≠ÁªÉÊêúÁ¥¢Êü•ËØ¢È¢ÑÊµãÊ®°ÂûãÔºåËÄå‰∏çÈúÄË¶ÅÂ∞ÜÊØè‰∏™ÊêúÁ¥¢ÁªìÊûúÂèëÈÄÅÂõûË∞∑Ê≠å„ÄÇ</em></p>
</blockquote>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 CA77
    </section>
    
    <section class="powerby">
        
            Cover images all from https://unsplash.com/ <br/>
        ‰ΩøÁî® <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> ÊûÑÂª∫ <br />
        ‰∏ªÈ¢ò <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.27.0">Stack</a></b> Áî± <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> ËÆæËÆ°
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
